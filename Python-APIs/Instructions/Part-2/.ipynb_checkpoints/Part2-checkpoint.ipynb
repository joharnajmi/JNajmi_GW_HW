{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target User\n",
    "target_users = ['@bbcworld', '@cbsnews', '@cnn', '@foxnews', '@nytimes']\n",
    "\n",
    "# Set Lists\n",
    "users_list = []\n",
    "pos_list = []\n",
    "neu_list = []\n",
    "neg_list = []\n",
    "compound_list = []\n",
    "timestamp_list = []\n",
    "text_list = []\n",
    "tweet_count = []\n",
    "sentiment_list = []\n",
    "\n",
    "#cycle through the different users\n",
    "for target_user in target_users:\n",
    "    users_list1 = []\n",
    "    content_list1 = []\n",
    "    pos_list1 = []\n",
    "    neu_list1 = []\n",
    "    neg_list1 = []\n",
    "    compound_list1 = []\n",
    "    timestamp_list1 = []\n",
    "    text_list1 = []\n",
    "    tweet_count1 = []\n",
    "    tweetcount = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "#start looking up each tweet - for loop range 5 so that 20 tweets per \n",
    "    for i in range(5):\n",
    "        tweets = api.user_timeline(target_user, page=i)\n",
    "        \n",
    "        for tweet in tweets:\n",
    "            text = tweet[\"text\"]\n",
    "            print(f\"{text}\")\n",
    "            timestamp = tweet[\"created_at\"]\n",
    "            pos = SIA.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neu = SIA.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            neg = SIA.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "            compound = SIA.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            users_list1.append(tweet[\"user\"][\"screen_name\"])\n",
    "            timestamp_list1.append(timestamp)\n",
    "            compound_list1.append(compound)\n",
    "            pos_list1.append(pos)\n",
    "            neu_list1.append(neu)\n",
    "            neg_list1.append(neg)\n",
    "            text_list1.append(text)\n",
    "            tweetcount += 1\n",
    "            tweet_count1.append(tweetcount)\n",
    "    \n",
    "    users_list.append(users_list1)\n",
    "    pos_list.append(pos_list1)\n",
    "    neu_list.append(neu_list1)\n",
    "    neg_list.append(neg_list1)\n",
    "    compound_list.append(compound_list1)\n",
    "    timestamp_list.append(timestamp_list1)\n",
    "    text_list.append(text_list1)\n",
    "    tweet_count.append(tweet_count1)    \n",
    "    \n",
    "    \n",
    "sentiments = np.mean(compound_list)\n",
    "sentiment_list.append(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = np.array(users_list).flatten().tolist()\n",
    "tweet_count = np.array(tweet_count).flatten().tolist()\n",
    "text_list = np.array(text_list).flatten().tolist()\n",
    "timestamp_list = np.array(timestamp_list).flatten().tolist()\n",
    "compound_list = np.array(compound_list).flatten().tolist()\n",
    "pos_list = np.array(pos_list).flatten().tolist()\n",
    "neu_list = np.array(neu_list).flatten().tolist()\n",
    "neg_list = np.array(neg_list).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = {\n",
    "    'User': users_list,\n",
    "    'Tweet Count': tweet_count,\n",
    "    'Tweet': text_list,\n",
    "    'Timestamp': timestamp_list,\n",
    "    'Compound Score': compound_list,\n",
    "    'Positive Score': pos_list,\n",
    "    'Neutral Score': neu_list,\n",
    "    'Negative Score': neg_list\n",
    "}\n",
    "sentiment_df = pd.DataFrame(sentiments)\n",
    "sentiment_df.to_csv(\"Sentiment.csv\", index=False, header=True)\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.xlabel(\"Tweet Count\")\n",
    "plt.title(\"Sentiment Analysis of the 5 News Sources\")\n",
    "plt.grid\n",
    "plt.savefig(\"Sentiment_Analysis_Chart.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
