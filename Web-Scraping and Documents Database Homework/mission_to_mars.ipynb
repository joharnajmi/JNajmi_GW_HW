{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # numpy library\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas library\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser module from splinter library\n",
    "from splinter import Browser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webdriver module from selenium library\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup module from bs4 library\n",
    "from bs4 import BeautifulSoup as bs                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests library\n",
    "import requests as req "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes empty dictionary\n",
    "news_data = {}\n",
    "\n",
    "# initializes empty list\n",
    "paragraph_text = []                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base URL for finding paragraph text\n",
    "\n",
    "base_url = \"https://mars.nasa.gov/\"   \n",
    "\n",
    "# URL for initial scrape\n",
    "nasa_url = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "# acquires first response from URL\n",
    "response_1 = req.get(nasa_url)                                               \n",
    "\n",
    "# sends response to beautiful soup\n",
    "nasa_soup = bs(response_1.text, 'html.parser')                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds class\n",
    "soup_div = nasa_soup.find(class_=\"slide\")\n",
    "\n",
    "# finds all anchors\n",
    "soup_news = soup_div.find_all('a')\n",
    "\n",
    "# extracts and cleans title\n",
    "news_title = soup_news[1].get_text().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # finds paragraphs\n",
    "soup_p = soup_div.find_all('a', href=True)\n",
    "\n",
    "# gets paragraphs URL\n",
    "soup_p_url = soup_p[0]['href']\n",
    "\n",
    "# concatenates URL for paragraph\n",
    "paragraph_url = base_url + soup_p_url\n",
    "\n",
    "# acquires second response from URL\n",
    "response_2 = req.get(paragraph_url)\n",
    "\n",
    "# sends response to beautiful soup\n",
    "para_soup = bs(response_2.text, \"html.parser\") \n",
    "\n",
    "# finds class\n",
    "ww_paragraphs = para_soup.find(class_='wysiwyg_content')\n",
    "\n",
    "# finds paragraphs\n",
    "paragraphs = ww_paragraphs.find_all('p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterates through paragraphs\n",
    "# extracts and cleans paragraphs \n",
    "# appends to list\n",
    "for paragraph in paragraphs:\n",
    "    clean_paragraph = paragraph.get_text().strip()                              \n",
    "    paragraph_text.append(clean_paragraph)                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # adds title to dictionary\n",
    "news_data[\"news_title\"] = news_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds paragraph summary to dictionary\n",
    "news_data[\"paragraph_text_1\"] = paragraph_text[0]                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds paragraph detail to dictionary\n",
    "news_data[\"paragraph_text_2\"] = paragraph_text[1]                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_title': 'NASA Invites Students to Name Mars 2020 Rover',\n",
       " 'paragraph_text_1': 'Red rover, red rover, send a name for Mars 2020 right over! NASA is recruiting help from students nationwide to find a name for its next Mars rover mission.',\n",
       " 'paragraph_text_2': 'Starting Tuesday, Aug. 27, K-12 students in U.S. public, private and home schools can enter the Mars 2020 Name the Rover essay contest. One grand prize winner will name the rover and be invited to see the spacecraft launch in July 2020 from Cape Canaveral Air Force Station in Florida.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displays dictionary\n",
    "news_data                                                                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
